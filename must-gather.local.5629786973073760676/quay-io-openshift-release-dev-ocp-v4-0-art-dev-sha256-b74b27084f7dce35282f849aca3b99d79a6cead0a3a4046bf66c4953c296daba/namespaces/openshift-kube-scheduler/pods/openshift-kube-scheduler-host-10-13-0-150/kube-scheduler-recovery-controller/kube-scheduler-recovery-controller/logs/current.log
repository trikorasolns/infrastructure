2025-03-31T20:40:48.105365040Z + timeout 3m /bin/bash -exuo pipefail -c 'while [ -n "$(ss -Htanop \( sport = 11443 \))" ]; do sleep 1; done'
2025-03-31T20:40:48.107988479Z ++ ss -Htanop '(' sport = 11443 ')'
2025-03-31T20:40:48.111234348Z + '[' -n '' ']'
2025-03-31T20:40:48.111626480Z + exec cluster-kube-scheduler-operator cert-recovery-controller --kubeconfig=/etc/kubernetes/static-pod-resources/configmaps/kube-scheduler-cert-syncer-kubeconfig/kubeconfig --namespace=openshift-kube-scheduler --listen=0.0.0.0:11443 -v=2
2025-03-31T20:40:48.148389070Z W0331 20:40:48.148249       1 cmd.go:245] Using insecure, self-signed certificates
2025-03-31T20:40:48.148528057Z I0331 20:40:48.148511       1 crypto.go:601] Generating new CA for cert-recovery-controller-signer@1743453648 cert, and key in /tmp/serving-cert-586892186/serving-signer.crt, /tmp/serving-cert-586892186/serving-signer.key
2025-03-31T20:40:48.477444489Z I0331 20:40:48.477401       1 leaderelection.go:122] The leader election gives 4 retries and allows for 30s of clock skew. The kube-apiserver downtime tolerance is 78s. Worst non-graceful lease acquisition is 2m43s. Worst graceful lease acquisition is {26s}.
2025-03-31T20:40:48.478108156Z I0331 20:40:48.478067       1 observer_polling.go:159] Starting file observer
2025-03-31T20:40:48.493029562Z I0331 20:40:48.492995       1 builder.go:299] cert-recovery-controller version v0.0.0-master+$Format:%H$-$Format:%H$
2025-03-31T20:40:48.519963459Z I0331 20:40:48.519823       1 leaderelection.go:250] attempting to acquire leader lease openshift-kube-scheduler/cert-recovery-controller-lock...
2025-03-31T20:40:48.525178439Z I0331 20:40:48.525154       1 leaderelection.go:260] successfully acquired lease openshift-kube-scheduler/cert-recovery-controller-lock
2025-03-31T20:40:48.525286596Z I0331 20:40:48.525250       1 event.go:298] Event(v1.ObjectReference{Kind:"Lease", Namespace:"openshift-kube-scheduler", Name:"cert-recovery-controller-lock", UID:"1a13eb17-bdf1-41aa-8370-5949f0bdd77a", APIVersion:"coordination.k8s.io/v1", ResourceVersion:"73418", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' host-10-13-0-150_ab23a605-5e95-45b9-9558-82e81d1ee46a became leader
2025-03-31T20:40:48.525824636Z I0331 20:40:48.525627       1 base_controller.go:67] Waiting for caches to sync for ResourceSyncController
2025-03-31T20:40:48.627021168Z I0331 20:40:48.626607       1 base_controller.go:73] Caches are synced for ResourceSyncController 
2025-03-31T20:40:48.627021168Z I0331 20:40:48.626629       1 base_controller.go:110] Starting #1 worker of ResourceSyncController controller ...
2025-03-31T20:42:58.590216929Z E0331 20:42:58.590124       1 leaderelection.go:332] error retrieving resource lock openshift-kube-scheduler/cert-recovery-controller-lock: Get "https://localhost:6443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-scheduler/leases/cert-recovery-controller-lock?timeout=1m47s": dial tcp [::1]:6443: connect: connection refused
2025-03-31T20:43:03.335630378Z E0331 20:43:03.335598       1 reflector.go:147] k8s.io/client-go@v0.28.3/tools/cache/reflector.go:229: Failed to watch *v1.ConfigMap: unknown (get configmaps)
2025-03-31T20:43:03.335672757Z E0331 20:43:03.335665       1 reflector.go:147] k8s.io/client-go@v0.28.3/tools/cache/reflector.go:229: Failed to watch *v1.Secret: unknown (get secrets)
2025-03-31T20:43:03.335695886Z E0331 20:43:03.335689       1 reflector.go:147] k8s.io/client-go@v0.28.3/tools/cache/reflector.go:229: Failed to watch *v1.ConfigMap: unknown (get configmaps)
2025-04-01T08:10:13.756171336Z E0401 08:10:13.756085       1 leaderelection.go:332] error retrieving resource lock openshift-kube-scheduler/cert-recovery-controller-lock: Get "https://localhost:6443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-scheduler/leases/cert-recovery-controller-lock?timeout=1m47s": dial tcp [::1]:6443: connect: connection refused
