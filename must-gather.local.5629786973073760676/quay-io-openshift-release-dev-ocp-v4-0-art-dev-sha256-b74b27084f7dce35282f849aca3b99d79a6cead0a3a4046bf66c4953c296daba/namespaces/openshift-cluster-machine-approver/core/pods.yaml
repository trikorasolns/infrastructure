---
apiVersion: v1
items:
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2025-03-31T20:17:18Z"
    generateName: machine-approver-6db5c9969f-
    labels:
      app: machine-approver
      pod-template-hash: 6db5c9969f
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:target.workload.openshift.io/management: {}
          f:generateName: {}
          f:labels:
            .: {}
            f:app: {}
            f:pod-template-hash: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"6c725c71-9254-411a-b629-5d4a7f5f9ef9"}: {}
        f:spec:
          f:containers:
            k:{"name":"kube-rbac-proxy"}:
              .: {}
              f:args: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:ports:
                .: {}
                k:{"containerPort":9192,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:hostPort: {}
                  f:name: {}
                  f:protocol: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/kube-rbac-proxy"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                k:{"mountPath":"/etc/tls/private"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
            k:{"name":"machine-approver-controller"}:
              .: {}
              f:args: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"RELEASE_VERSION"}:
                  .: {}
                  f:name: {}
                  f:value: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/var/run/configmaps/config"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:hostNetwork: {}
          f:nodeSelector: {}
          f:priorityClassName: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"auth-proxy-config"}:
              .: {}
              f:configMap:
                .: {}
                f:defaultMode: {}
                f:name: {}
              f:name: {}
            k:{"name":"config"}:
              .: {}
              f:configMap:
                .: {}
                f:defaultMode: {}
                f:name: {}
                f:optional: {}
              f:name: {}
            k:{"name":"machine-approver-tls"}:
              .: {}
              f:name: {}
              f:secret:
                .: {}
                f:defaultMode: {}
                f:secretName: {}
      manager: kube-controller-manager
      operation: Update
      time: "2025-03-31T20:17:18Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            .: {}
            k:{"type":"PodScheduled"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:message: {}
              f:reason: {}
              f:status: {}
              f:type: {}
      manager: kube-scheduler
      operation: Update
      subresource: status
      time: "2025-03-31T20:17:18Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.13.0.150"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2025-03-31T20:40:16Z"
    name: machine-approver-6db5c9969f-7kpws
    namespace: openshift-cluster-machine-approver
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: ReplicaSet
      name: machine-approver-6db5c9969f
      uid: 6c725c71-9254-411a-b629-5d4a7f5f9ef9
    resourceVersion: "72776"
    uid: b528b0b9-4c3e-4aab-a624-dbc6486c37a0
  spec:
    containers:
    - args:
      - --secure-listen-address=0.0.0.0:9192
      - --upstream=http://127.0.0.1:9191/
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      - --config-file=/etc/kube-rbac-proxy/config-file.yaml
      - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305
      - --logtostderr=true
      - --v=3
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:fedf41d919edda4f5513a26231124f55d8b6a65fe634b88ad0223fe7b3c26ec1
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9192
        hostPort: 9192
        name: https
        protocol: TCP
      resources:
        requests:
          cpu: 10m
          memory: 20Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /etc/kube-rbac-proxy
        name: auth-proxy-config
      - mountPath: /etc/tls/private
        name: machine-approver-tls
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-phffr
        readOnly: true
    - args:
      - --config=/var/run/configmaps/config/config.yaml
      - -v=2
      - --logtostderr
      - --leader-elect=true
      - --leader-elect-lease-duration=137s
      - --leader-elect-renew-deadline=107s
      - --leader-elect-retry-period=26s
      - --leader-elect-resource-namespace=openshift-cluster-machine-approver
      - --api-group-version=machine.openshift.io/v1beta1
      - --max-concurrent-reconciles=10
      command:
      - /usr/bin/machine-approver
      env:
      - name: RELEASE_VERSION
        value: 4.15.46
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:443e165b6e26692caa4707863dffe4a759c578aad267a038a21cad4e0a6550a4
      imagePullPolicy: IfNotPresent
      name: machine-approver-controller
      resources:
        requests:
          cpu: 10m
          memory: 50Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /var/run/configmaps/config
        name: config
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-phffr
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: host-10-13-0-150
    nodeSelector:
      node-role.kubernetes.io/master: ""
    preemptionPolicy: PreemptLowerPriority
    priority: 2000000000
    priorityClassName: system-cluster-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: machine-approver-sa
    serviceAccountName: machine-approver-sa
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoSchedule
      key: node-role.kubernetes.io/master
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 120
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 120
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        name: kube-rbac-proxy
      name: auth-proxy-config
    - name: machine-approver-tls
      secret:
        defaultMode: 420
        secretName: machine-approver-tls
    - configMap:
        defaultMode: 440
        name: machine-approver-config
        optional: true
      name: config
    - name: kube-api-access-phffr
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2025-03-31T20:21:49Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2025-03-31T20:40:16Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2025-03-31T20:40:16Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2025-03-31T20:21:49Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://484366a95ed5c3a4d6aed9b9f8088190a15ed8917fefce02c04f341399bb7b90
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:fedf41d919edda4f5513a26231124f55d8b6a65fe634b88ad0223fe7b3c26ec1
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:fedf41d919edda4f5513a26231124f55d8b6a65fe634b88ad0223fe7b3c26ec1
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2025-03-31T20:22:54Z"
    - containerID: cri-o://ad64f73c2586ff99f2d74976a3cf7f5972cf4dab03c03aa01ae4fd5343115d90
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:443e165b6e26692caa4707863dffe4a759c578aad267a038a21cad4e0a6550a4
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:443e165b6e26692caa4707863dffe4a759c578aad267a038a21cad4e0a6550a4
      lastState:
        terminated:
          containerID: cri-o://b235910e85fb8461dd3fe02d930246f01c1c40bc0e289c8ceb5b37366908d936
          exitCode: 255
          finishedAt: "2025-03-31T20:40:04Z"
          message: |
            ver","name":"cluster-machine-approver-leader","uid":"68566c58-c87d-460d-bbc9-577837b62366","apiVersion":"coordination.k8s.io/v1","resourceVersion":"65881"} reason="LeaderElection"
            I0331 20:32:24.259303       1 controller.go:178] "Starting EventSource" controller="certificatesigningrequest" controllerGroup="certificates.k8s.io" controllerKind="CertificateSigningRequest" source="kind source: *v1.CertificateSigningRequest"
            I0331 20:32:24.259311       1 controller.go:178] "Starting EventSource" controller="certificatesigningrequest" controllerGroup="certificates.k8s.io" controllerKind="CertificateSigningRequest" source="kind source: *v1.ConfigMap"
            I0331 20:32:24.259319       1 controller.go:186] "Starting Controller" controller="certificatesigningrequest" controllerGroup="certificates.k8s.io" controllerKind="CertificateSigningRequest"
            I0331 20:32:24.259654       1 status.go:97] Starting cluster operator status controller
            I0331 20:32:24.472249       1 controller.go:220] "Starting workers" controller="certificatesigningrequest" controllerGroup="certificates.k8s.io" controllerKind="CertificateSigningRequest" worker count=10
            E0331 20:39:02.445560       1 leaderelection.go:332] error retrieving resource lock openshift-cluster-machine-approver/cluster-machine-approver-leader: the server was unable to return a response in the time allotted, but may still be processing the request (get leases.coordination.k8s.io cluster-machine-approver-leader)
            E0331 20:39:49.443189       1 leaderelection.go:332] error retrieving resource lock openshift-cluster-machine-approver/cluster-machine-approver-leader: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-cluster-machine-approver/leases/cluster-machine-approver-leader": context deadline exceeded
            I0331 20:39:49.443238       1 leaderelection.go:285] failed to renew lease openshift-cluster-machine-approver/cluster-machine-approver-leader: timed out waiting for the condition
            F0331 20:40:04.474031       1 main.go:235] unable to run the manager: leader election lost
          reason: Error
          startedAt: "2025-03-31T20:32:19Z"
      name: machine-approver-controller
      ready: true
      restartCount: 2
      started: true
      state:
        running:
          startedAt: "2025-03-31T20:40:16Z"
    hostIP: 10.13.0.150
    phase: Running
    podIP: 10.13.0.150
    podIPs:
    - ip: 10.13.0.150
    qosClass: Burstable
    startTime: "2025-03-31T20:21:49Z"
kind: PodList
metadata:
  resourceVersion: "718260"
