---
- name: "Collect information"
  import_playbook: _common_ocp.yaml
  when: ocp_cluster_id_tag is not defined

- name: "Fetch kubeadmin account from installation"
  hosts: "ocp_services"
  gather_facts: true
  vars:
    - k8s_version: 1.33

  tasks:
  - name: "Read Openshift Install State"
    ansible.builtin.shell: |
      dnf update -y
    become: true

  - name: "Read Openshift Install State"
    ansible.builtin.shell: |
      sudo systemctl stop swap-create@zram0
      sudo dnf remove zram-generator-defaults
    become: true
    failed_when: false

  - name: "Restart"
    ansible.builtin.shell: |
      reboot now
    become: true

  - name: "Reboot and wait"
    ansible.builtin.shell: |
      reboot now
    become: true

  - name: "Reboot and wait"
    ansible.builtin.shell: |
      systemctl disable --now firewalld
      dnf install iptables iproute-tc
    become: true


  - name: "Reboot and wait"
    ansible.builtin.shell: |
      cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
      overlay
      br_netfilter
      EOF
    become: true


[source,bash]
----
sudo cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF
----

[source,bash]
----
sudo sysctl --system
sudo reboot now
----

Verify

[source,bash]
----
lsmod | grep br_netfilter
lsmod | grep overlay
----

[source,bash]
----
sysctl net.bridge.bridge-nf-call-iptables net.bridge.bridge-nf-call-ip6tables net.ipv4.ip_forward
----

[source,bash]
----
sudo dnf install cri-o1.33 containernetworking-plugins
----

[source,bash]
----
sudo dnf list kubernetes1.33
----

[source,bash]
----
sudo dnf install kubernetes1.33 kubernetes1.33-kubeadm kubernetes1.33-client
----

[source,bash]
----
sudo systemctl enable --now crio
----

[source,bash]
----
sudo kubeadm config images pull
----

=== Initialize cluster

Initialize the cluster or join an existing cluster.

[source,bash]
----
sudo kubeadm init --pod-network-cidr=10.244.0.0/16
----

==== Join an existing cluster

Get the token.

[source,bash]
----
$ kubeadm token list
TOKEN                     TTL         EXPIRES                USAGES                   DESCRIPTION                                                EXTRA GROUPS
yyyyyy.xxxxxxxxxxxxxxxx   6h          2025-08-31T21:18:33Z   authentication,signing   The default bootstrap token generated by 'kubeadm init'.   system:bootstrappers:kubeadm:default-node-token
----

sudo kubeadm join 192.168.1.10:6443 --token yyyyyy.xxxxxxxxxxxxxxxx  --discovery-token-ca-cert-hash sha256:c8b0501c4ac0fb76a01b876c053b115283416d5cc73af66b90714582b08f733f --control-plane

sudo kubeadm join 192.168.1.10:6443 --token yyyyyy.xxxxxxxxxxxxxxxx  --discovery-token-ca-cert-hash sha256:c8b0501c4ac0fb76a01b876c053b115283416d5cc73af66b90714582b08f733f --control-plane

=== Taint nodes

Control plane.

kubectl taint nodes --all node-role.kubernetes.io/control-plane=control-plane

Remove Control plane.

kubectl taint nodes --all node-role.kubernetes.io/control-plane-

=== Lock the Kubernetes major.minor version

[source,bash]
----
sudo dnf versionlock add kubernetes*-1.33.* cri-o-1.33.*
----...
